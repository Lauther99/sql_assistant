{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\lauth\\\\OneDrive\\\\Desktop\\\\sql_assistant_v3\")\n",
    "from src.components.memory.memory import Memory\n",
    "from src.components.collector.collector import AppDataCollector, LLMResponseCollector\n",
    "from src.components.models.llms.llms import Langchain_OpenAI_LLM, HF_Llama38b_LLM\n",
    "from src.components.models.embeddings.embeddings import HF_MultilingualE5_Embeddings, Openai_Embeddings\n",
    "from src.components.memory.memory import Memory\n",
    "\n",
    "# Iniciando modelos LLM\n",
    "langchain_llm = Langchain_OpenAI_LLM()\n",
    "langchain_llm.init_model()\n",
    "hf_llm = HF_Llama38b_LLM()\n",
    "hf_llm.init_model()\n",
    "\n",
    "# Iniciando modelos Embeddings\n",
    "mle5_embeddings = HF_MultilingualE5_Embeddings()\n",
    "mle5_embeddings.init_model()\n",
    "\n",
    "openai_embeddings = Openai_Embeddings()\n",
    "openai_embeddings.init_model()\n",
    "\n",
    "# Iniciando memoria\n",
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.app.pipeline_processes.query_post_process.manager import query_post_process\n",
    "from src.app.pipeline_processes.query_pre_process.manager import (\n",
    "    query_pre_process,\n",
    "    simple_request_process,\n",
    ")\n",
    "from src.app.pipeline_processes.sql_generation_process.manager import (\n",
    "    complex_request_sql_generation,\n",
    ")\n",
    "from src.app.pipeline_processes.sql_post_process.manager import (\n",
    "    complex_request_pre_query_generation,\n",
    "    complex_request_sql_summary_response,\n",
    "    complex_request_sql_verification,\n",
    ")\n",
    "from src.app.pipeline_processes.sql_pre_process.manager import (\n",
    "    complex_request_process_modification,\n",
    "    complex_request_process_semantics,\n",
    ")\n",
    "from src.utils.sql_utils import run_sql\n",
    "import traceback\n",
    "import pandas as pd\n",
    "\n",
    "def pre_process_pipeline(\n",
    "    memory: Memory, collector: AppDataCollector, llm_collector: LLMResponseCollector\n",
    "):\n",
    "    try:\n",
    "        query_pre_process(\n",
    "            llm=hf_llm, memory=memory, collector=collector, llm_collector=llm_collector\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en: query_pre_process:\\n {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "def simple_request_pipeline(\n",
    "    memory: Memory, collector: AppDataCollector, llm_collector: LLMResponseCollector\n",
    "):\n",
    "    try:\n",
    "        simple_request_process(\n",
    "            llm=langchain_llm,\n",
    "            memory=memory,\n",
    "            collector=collector,\n",
    "            llm_collector=llm_collector,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en: simple_request_process:\\n {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "def complex_request_pipeline(\n",
    "    collector: AppDataCollector, llm_collector: LLMResponseCollector, memory: Memory\n",
    "):\n",
    "    try:\n",
    "        print(\"complex_request_process_modification\")\n",
    "        complex_request_process_modification(\n",
    "            llm=hf_llm,\n",
    "            embeddings=mle5_embeddings,\n",
    "            memory=memory,\n",
    "            collector=collector,\n",
    "            llm_collector=llm_collector,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en: complex_request_process_modification:\\n {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    try:\n",
    "        print(\"complex_request_process_semantics\")\n",
    "        complex_request_process_semantics(\n",
    "            llm=hf_llm,\n",
    "            embeddings=openai_embeddings,\n",
    "            collector=collector,\n",
    "            llm_collector=llm_collector,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en: complex_request_process_semantics:\\n {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    try:\n",
    "        print(\"complex_request_sql_generation\")\n",
    "        complex_request_sql_generation(\n",
    "            llm=langchain_llm, collector=collector, llm_collector=llm_collector\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en: complex_request_sql_generation:\\n {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    try:\n",
    "        print(\"complex_request_sql_verification\")\n",
    "        complex_request_sql_verification(\n",
    "            llm=hf_llm, collector=collector, llm_collector=llm_collector\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error en: complex_request_sql_verification:\\n {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    is_prequery = collector.assistant_sql_code_class.strip() == \"incomplete\"\n",
    "    if is_prequery:\n",
    "        try:\n",
    "            print(\"complex_request_pre_query_generation\")\n",
    "            complex_request_pre_query_generation(\n",
    "                llm=langchain_llm, collector=collector, llm_collector=llm_collector\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error en: complex_request_pre_query_generation:\\n {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "def post_process_pipeline(\n",
    "    user_message: str, collector: AppDataCollector, llm_collector: LLMResponseCollector\n",
    "):\n",
    "    df = None\n",
    "    is_prequery = (\n",
    "        collector.assistant_sql_code_class.strip() == \"incomplete\"\n",
    "        if collector.assistant_sql_code_class\n",
    "        else False\n",
    "    )\n",
    "\n",
    "    if is_prequery:\n",
    "        try:\n",
    "            print(\"Ejecutando codigo SQL de prequery ...\")\n",
    "            df = run_sql(collector.sql_pre_query)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar collector.sql_pre_query \\n{e}\")\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        try:\n",
    "            print(\"Ejecutando codigo SQL ...\")\n",
    "            df = run_sql(collector.sql_code)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar collector.sql_code \\n{e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        try:\n",
    "            complex_request_sql_summary_response(\n",
    "                llm=langchain_llm,\n",
    "                collector=collector,\n",
    "                llm_collector=llm_collector,\n",
    "                dataframe=df,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar complex_request_sql_summary_response\\n{e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    query_post_process(\n",
    "        llm=langchain_llm,\n",
    "        collector=collector,\n",
    "        user_message=user_message,\n",
    "        llm_collector=llm_collector,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_sql(\n",
    "    memory: Memory,\n",
    "    collector: AppDataCollector,\n",
    "    llm_collector: LLMResponseCollector,\n",
    "    user_message: str,\n",
    "):\n",
    "\n",
    "\n",
    "    pre_process_pipeline(\n",
    "        memory=memory, collector=collector, llm_collector=llm_collector\n",
    "    )\n",
    "    is_simple = collector.request_type.lower().strip() == \"simple\"\n",
    "\n",
    "    if is_simple:\n",
    "        simple_request_pipeline(\n",
    "            memory=memory, collector=collector, llm_collector=llm_collector\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        complex_request_pipeline(\n",
    "            collector=collector, llm_collector=llm_collector, memory=memory\n",
    "        )\n",
    "\n",
    "    post_process_pipeline(\n",
    "        user_message=user_message, collector=collector, llm_collector=llm_collector\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def chat(\n",
    "    user_message: str,\n",
    "    memory: Memory,\n",
    "    collector: AppDataCollector,\n",
    "    llm_collector: LLMResponseCollector,\n",
    "):\n",
    "    memory.add_user_message(user_message)\n",
    "    generate_sql(\n",
    "        memory=memory,\n",
    "        collector=collector,\n",
    "        llm_collector=llm_collector,\n",
    "\n",
    "        user_message=user_message,\n",
    "    )\n",
    "    ai_message = collector.ai_post_response\n",
    "    dataframe : pd.DataFrame | None = collector.dataframe_response\n",
    "    memory.add_ai_message(ai_message, dataframe)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate-request\n",
      "{'text': '\\nintention:  The human is seeking the static pressure.'} \n",
      "\n",
      "\n",
      "request-type\n",
      "{'text': \"\\ntype:  complex\\nanalysis: I see this is a general question about a measurement system property, but I don't have access to the measurement system database, so this type is complex.\"} \n",
      "\n",
      "\n",
      "complex_request_process_modification\n",
      "summary-conversation\n",
      "{'text': '\\nnew_summary:  The conversation is about a human asking the assistant for temperature and pressure data, specifically the average temperature for EMED-3138.12-050 in August 2023, and now requesting the static pressure.'} \n",
      "\n",
      "\n",
      "technical-terms\n",
      "{'text': '\\nterms: static pressure, temperature, system, EMED-3138.12-050'} \n",
      "\n",
      "\n",
      "enhanced-request-conversation\n",
      "{'text': '\\nresponse:  The human is requesting a summary of the previous conversation, specifically the request for static pressure information, which is relevant to the measurement system mentioned as EMED-3138.12-050.'} \n",
      "\n",
      "\n",
      "has-multi-definition\n",
      "{'text': '\\nclass: unclear\\nanalysis: The sentence contains the technical terms \"static pressure\", \"temperature\", \"system\", and \"EMED-3138.12-050\". However, \"temperature\" is not mentioned in the sentence, but \"static pressure\" and \"system\" have multiple definitions. \"EMED-3138.12-050\" has multiple possible meanings, including being the name of the measurement system or a firmware/version. The sentence does not provide enough context to determine which definition is being referred'} \n",
      "\n",
      "\n",
      "multi-definition-question\n",
      "{'text': '\\nquestion: What specific information are you looking for regarding static pressure and the measurement system EMED-3138.12-050, and which definition of these terms are you referring to?\\n\\nanalysis: The question asks the user to clarify the scope of the request and specify the meanings of technical terms to avoid ambiguity.'} \n",
      "\n",
      "\n",
      "final-request\n",
      "{'text': '\\nmodified_sentence: \"The human is requesting the static pressure of the measurement system EMED-3138.12-050 previously discussed.\"\\nanalysis: The request is refined to include specific information regarding the measurement system, omitting the original request for a summary.'} \n",
      "\n",
      "\n",
      "modified-request\n",
      "{'text': '\\nmodified_sentence: \"The human is requesting the variable of the measurement system measurement system previously discussed.\"'} \n",
      "\n",
      "\n",
      "complex_request_process_semantics\n",
      "semantic-tables\n",
      "{'text': '\\ntables:  med_tipo_medicion, med_sistema_medicion, med_tag, fcs_computador_medidor, var_tipo_variable, var_variable_datos'} \n",
      "\n",
      "\n",
      "complex_request_sql_generation\n",
      "generate-sql\n",
      "{'text': \"sql_query: SELECT var.Valor AS 'Static Pressure', med.Tag AS 'Measurement System Tag' FROM dbo_v2.var_variable_datos AS var INNER JOIN dbo_v2.med_sistema_medicion AS med ON var.idSistemaMedicion_fk = med.Id INNER JOIN dbo_v2.var_tipo_variable AS vtv ON vtv.Id = var.idVariable_fk WHERE med.Tag = 'EMED-3138.12-050' AND vtv.Nombre = 'Pressão Estática (kPa)'\\n\\nsuggestion: It would be helpful to specify a date or time frame for the requested static pressure. Also, it may be useful to include an ORDER BY clause to sort the results in a specific order.\\n\\nused_tables: dbo_v2.var_variable_datos, dbo_v2.med_sistema_medicion, dbo_v2.var_tipo_variable\\n\\ntable_schema: dbo_v2\"} \n",
      "\n",
      "\n",
      "complex_request_sql_verification\n",
      "classify-sql\n",
      "{'text': '\\nclass: \"complete\"\\nanalysis: The SQL query is complete and can be executed as is, as it includes all necessary information, such as table names, column names, join conditions, filter conditions, and an alias for the selected columns.\\nsuggestion: None, the query looks good and can be executed without any modifications.'} \n",
      "\n",
      "\n",
      "Ejecutando codigo SQL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lauth\\OneDrive\\Desktop\\sql_assistant_v3\\src\\utils\\sql_utils.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(sql, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary-response-sql\n",
      "{'text': 'response: The static pressure of the measurement system EMED-3138.12-050 is 367.521.'} \n",
      "\n",
      "\n",
      "post-process-translation\n",
      "{'text': 'detected_language: English\\nresponse: The static pressure of the measurement system EMED-3138.12-050 is 367.521.'} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iniciando collector\n",
    "collector = AppDataCollector()\n",
    "llm_collector = LLMResponseCollector()\n",
    "# memory.clear_memory()\n",
    "\n",
    "chat(\"Now I want the static pressure\", memory, collector, llm_collector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "I need your help. Follow carefully the next steps:\n",
      "\n",
      "First, look up the next user request:\n",
      "user_request: '''\"The human is requesting the static pressure of the measurement system EMED-3138.12-050 previously discussed.\"'''\n",
      "\n",
      "Second, the next is a pandas dataframe that answers the previous request. Pay attention to this information:\n",
      "\n",
      "|    |   Static Pressure | Measurement System Tag   |\n",
      "|---:|------------------:|:-------------------------|\n",
      "|  0 |           367.521 | EMED-3138.12-050         |\n",
      "|  1 |           387.26  | EMED-3138.12-050         |\n",
      "|  2 |           372.419 | EMED-3138.12-050         |\n",
      "|  3 |           367.056 | EMED-3138.12-050         |\n",
      "|  4 |           350.407 | EMED-3138.12-050         |\n",
      "|  5 |           323.005 | EMED-3138.12-050         |\n",
      "|  6 |           338.355 | EMED-3138.12-050         |\n",
      "|  7 |           338.145 | EMED-3138.12-050         |\n",
      "|  8 |           363.991 | EMED-3138.12-050         |\n",
      "|  9 |           377.704 | EMED-3138.12-050         |\n",
      "\n",
      "Third, generation. Generate a brief response to the user request based on the previous dataframe.\n",
      "\n",
      "Fourth, evaluation. Evaluate if your response is answering the user request.\n",
      "\n",
      "Note:\n",
      " - Do not include any explanations or apologies in your response.\n",
      " - Do not add your own conclusions or clarifications.\n",
      " - If dataframe is empty, say that the response is not available.\n",
      "\n",
      "Note: You can make brief suggestion for user query to mention dates or names to retrieve better information from database.\n",
      "\n",
      "Use the following key format to respond:\n",
      "response: Your briefly response.\n",
      "\n",
      "Begin!\n"
     ]
    }
   ],
   "source": [
    "print(len(llm_collector.llm_responses))\n",
    "print(llm_collector.llm_responses[12].prompt) #! what is the human currently requesting [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(collector.semantic_info.keys())\n",
    "print(json.dumps(collector.terms_dictionary, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human line: Give me the average temperature for EMED-3138.12-050 in august 2023\n",
      "Assistant line: The average temperature for EMED-3138.12-050 in August 2023 is 23.502.\n",
      "Assistant DataFrame: \n",
      "|    |   Average Temperature |\n",
      "|---:|----------------------:|\n",
      "|  0 |                23.502 |\n",
      "Human line: Now I want the static pressure\n",
      "Assistant line: The static pressure of the measurement system EMED-3138.12-050 is 367.521.\n",
      "Assistant DataFrame: \n",
      "|    |   Static Pressure | Measurement System Tag   |\n",
      "|---:|------------------:|:-------------------------|\n",
      "|  0 |           367.521 | EMED-3138.12-050         |\n",
      "|  1 |           387.26  | EMED-3138.12-050         |\n",
      "|  2 |           372.419 | EMED-3138.12-050         |\n",
      "|  3 |           367.056 | EMED-3138.12-050         |\n",
      "|  4 |           350.407 | EMED-3138.12-050         |\n",
      "|  5 |           323.005 | EMED-3138.12-050         |\n",
      "|  6 |           338.355 | EMED-3138.12-050         |\n",
      "|  7 |           338.145 | EMED-3138.12-050         |\n",
      "|  8 |           363.991 | EMED-3138.12-050         |\n",
      "|  9 |           377.704 | EMED-3138.12-050         |\n"
     ]
    }
   ],
   "source": [
    "print(memory.get_chat_history_lines(memory.chat_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.add_ai_message(\"hi\", None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
